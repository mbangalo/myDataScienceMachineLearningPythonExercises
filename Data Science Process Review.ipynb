{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review of the process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns; sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Iris data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data = pd.read_csv(\"iris.csv\", names = [\"sepal_l\", \"sepal_w\", \"petal_l\", \"petal_w\", \"class\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_plot = sns.pairplot(iris_data, hue='class')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean, impute, transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "fill_nan = Imputer(missing_values=np.nan, strategy=\"mean\", axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection, feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop returns a copy\n",
    "# df = iris_data.drop(['some_feature'], axis=1) \n",
    "\n",
    "# feature engineering\n",
    "# df[\"new_feature\"] = df[\"feature_1\"] * df[\"feature_2\"]\n",
    "\n",
    "# lambda function\n",
    "# f = lambda x: x**2            \n",
    "# df[\"new_feature\"].map(f)  # for element-wise application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get X and y\n",
    "X = iris_data[[\"sepal_l\", \"sepal_w\", \"petal_l\", \"petal_w\"]].values\n",
    "\n",
    "# Transform 'Iris-virginica' to be the positive class (binary classification)\n",
    "y = iris_data['class'].map({\"Iris-setosa\":0, 'Iris-versicolor':1, 'Iris-virginica': 0}).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split dataset into test/train  using All features\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale/Standardize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# scale/standardize features\n",
    "stdsc = StandardScaler()\n",
    "X_train_std = stdsc.fit_transform(X_train)\n",
    "X_test_std = stdsc.transform(X_test) \n",
    "X_train_std[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "# --- Key Parameters ---\n",
    "# C: the regularization strength (smaller values for greater regularization); default is 1.0\n",
    "# penalty: used to specify the penalization used for regularizartion; default is l2\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg = LogisticRegression(C = 1)\n",
    "\n",
    "# Support Vector Machine\n",
    "# --- Key Parameters ---\n",
    "# C: how much penalty there is for misclassification (smaller values for greater penalty); default is 1.0\n",
    "# kernel: specifies the kernel type to be used (often 'rbf' or 'linear'); default is 'rbf'\n",
    "# gamma: the coefficient for non-linear kernels\n",
    "from sklearn.svm import SVC\n",
    "svm = SVC(kernel='linear', C=1)\n",
    "\n",
    "# Random Forest (ensemble of Decision Trees)\n",
    "# --- Key Parameters ---\n",
    "# n_estimators: the number of trees in the forest; default is 10\n",
    "# max_depth: the depth of the tree; defualt is None, full expansion\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = RandomForestClassifier(n_estimators=10, random_state=0)\n",
    "\n",
    "# k-Nearest Neighbor\n",
    "# --- Key Parameters ---\n",
    "# n_neighbors: number of neighbors to use; default is 5\n",
    "# weights: weight function used; default is 'uniform'\n",
    "        # 'uniform' means all points are weighted equally; '\n",
    "        # 'distance' means closer points have greater influence;\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Neural Network\n",
    "# --- Key Parameters ---\n",
    "# hidden_layer_sizes: a tuple representing the number of nodes for respective layer; default is (100,)\n",
    "# activation: the activation function for the hidden layer; defualt is 'relu'\n",
    "        # usually 'relu', 'tanh', or 'sigmoid'\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "nn = MLPClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(log_reg, X_train_std, y_train, scoring='accuracy', cv=10)\n",
    "\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())               # accuracy measure\n",
    "    print(\"Standard deviation:\", scores.std())  # std measures how precise the measure is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_scores(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [log_reg, knn, svm, forest, nn]\n",
    "\n",
    "model_scores = []\n",
    "for clf in classifiers:\n",
    "    model_scores.append(cross_val_score(clf, X_train_std, y_train, scoring='accuracy', cv=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_df = pd.DataFrame(model_scores, columns=[1,2,3,4,5,6,7,8,9,10],\n",
    "                               index=[\"LR\", \"KNN\", \"SVM\", \"Forest\", \"NN\"])\n",
    "models_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_df[\"Mean\"] = models_df.mean(axis=1)\n",
    "models_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boxplot and Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BOXPLOT comparing models and comparing SVM using different feature subsets\n",
    "fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(18, 8))\n",
    "# rectangular box plot\n",
    "bplot_models = axes.boxplot(model_scores, vert=True, patch_artist=True)\n",
    "\n",
    "# fill with colors - Models\n",
    "colors_d = [\"lightgreen\", \"lightyellow\", \"lime\", \"yellow\", \"yellowgreen\"]\n",
    "for patch, color in zip(bplot_models['boxes'], colors_d):\n",
    "    patch.set_facecolor(color)\n",
    "    \n",
    "    # adding axes labels\n",
    "axes.yaxis.grid(True)\n",
    "axes.set_xticks([y+1 for y in range(len(model_scores))])\n",
    "axes.set_xlabel('Classification Models', fontsize=18)\n",
    "axes.set_ylabel('Accuracy', fontsize=18)\n",
    "axes.set_ylim((.4, 1.1))\n",
    "axes.set_title('Classification Accuracy using All Features', fontsize = 18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning (on selected models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter tuning can be done manually or using Grid Search with Cross-validation\n",
    "\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "# Grid Search\n",
    "param_range = [0.0001, 0.001, .005, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]\n",
    "gs = GridSearchCV(estimator=log_reg, param_grid=[{'C': param_range}], scoring='accuracy', cv=3)\n",
    "\n",
    "# Cross Validation, evaluates the returned model\n",
    "cross_val_score(gs, X_train_std, y_train, scoring='accuracy', cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrain tuned model using ALL Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.fit(X_train, y_train)\n",
    "train_score = gs.score(X_train, y_train)\n",
    "test_score = gs.score(X_test, y_test)\n",
    "print(\"Train score: {} \\nTest score: {}\".format(train_score, test_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "forest.fit(X_train, y_train)\n",
    "y_pred = forest.predict(X_test)\n",
    "confmat = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "ax.matshow(confmat, cmap=plt.cm.Blues, alpha=0.3)\n",
    "for i in range(confmat.shape[0]):\n",
    "    for j in range(confmat.shape[1]):\n",
    "        ax.text(x=j, y=i, s=confmat[i, j], va='center', ha='center')\n",
    "plt.xlabel('predicted label')\n",
    "plt.ylabel('true label')\n",
    "\n",
    "# Precision, Recall, and F1 scores\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "precision = precision_score(y_true=y_test, y_pred=y_pred)\n",
    "recall = recall_score(y_true=y_test, y_pred=y_pred)\n",
    "f1 = f1_score(y_true=y_test, y_pred=y_pred)\n",
    "\n",
    "#print('Precision: {:.3f}, Recall: {:.3f}, F1: {:.3f}'.format(precision, recall, f1))\n",
    "print(classification_report(y_test, y_pred, target_names=[\"other\", \"versicolor\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train final model on FULL dataset (ALL Training and Test data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "# scale/standardize X (the original full dataset)\n",
    "X_std = stdsc.fit_transform(X)\n",
    "\n",
    "forest.fit(X_std, y_)\n",
    "\n",
    "# save the model to disk\n",
    "joblib.dump(forest, 'final_forest_model.sav')\n",
    " \n",
    "# load the model from disk\n",
    "forest_final = joblib.load('final_forest_model.sav')\n",
    "\n",
    "# use the model as before\n",
    "accuracy = forest_final.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab Homework #2\n",
    "\n",
    "Using the Pima Indian dataset, build the best machine learning model that you can to predict whether or not the women in the dataset have diabetes.\n",
    "\n",
    "• Clean and transform the data as you desire\n",
    "\n",
    "• Summarize and/or visualize the data \n",
    "\n",
    "• Standardize the data\n",
    "\n",
    "• Choose 2-5 algorithms and perform 10-fold cross validation\n",
    "\n",
    "• Display a boxplot and select the best performing model\n",
    "\n",
    "• Tune its hyperparameters (manually or using grid search)\n",
    "\n",
    "• Train the same algorithm on your full training set (no cross validation)   ( model.fit(X_std_train, y_train))\n",
    "\n",
    "• Test the model on your test set ( model.score(X_test, y_test) )\n",
    "\n",
    "• Display the Precision, Recall, and F1 score metrics along with a confusion matrix \n",
    "\n",
    "• Be able to explain what the scores and confusion matrix mean pertaining to your data \n",
    "\n",
    "** Things to possibly try to improve your model's performance:\n",
    "\t\t\t\ttry different algorithms, tune the hyperparameters, Grid Search, \n",
    "\t\t\t\ttry a different scaler (standardization vs. normalization), imputation, feature engineering\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
